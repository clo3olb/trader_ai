Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DLinear_sin_wave_336_96', model='DLinear', data='custom', root_path='./predictor/dataset/', data_path='sin_wave.csv', result_path='./predictor/results/', features='M', target='Close', freq='h', date_header='timestamp', seq_len=336, label_len=48, pred_len=96, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, decoder_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=256, patience=100, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DLinear_sin_wave_336_96_DLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4298
val 582
test 1256
Epoch: 1 cost time: 1.7887365818023682
Epoch: 1, Steps: 16 | Train Loss: 1.3461936 Vali Loss: 1.3369741 Test Loss: 1.3294176
Validation loss decreased (inf --> 1.336974).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.928633451461792
Epoch: 2, Steps: 16 | Train Loss: 1.0857189 Vali Loss: 0.8436261 Test Loss: 0.8356985
Validation loss decreased (1.336974 --> 0.843626).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 0.9786524772644043
Epoch: 3, Steps: 16 | Train Loss: 0.6843045 Vali Loss: 0.5440717 Test Loss: 0.5347849
Validation loss decreased (0.843626 --> 0.544072).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 0.9147169589996338
Epoch: 4, Steps: 16 | Train Loss: 0.4560730 Vali Loss: 0.3876904 Test Loss: 0.3784844
Validation loss decreased (0.544072 --> 0.387690).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 0.9117977619171143
Epoch: 5, Steps: 16 | Train Loss: 0.3464596 Vali Loss: 0.3214245 Test Loss: 0.3113778
Validation loss decreased (0.387690 --> 0.321425).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 1.3749020099639893
Epoch: 6, Steps: 16 | Train Loss: 0.2989008 Vali Loss: 0.2923988 Test Loss: 0.2819760
Validation loss decreased (0.321425 --> 0.292399).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 1.164186716079712
Epoch: 7, Steps: 16 | Train Loss: 0.2772200 Vali Loss: 0.2788343 Test Loss: 0.2680027
Validation loss decreased (0.292399 --> 0.278834).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 0.928443193435669
Epoch: 8, Steps: 16 | Train Loss: 0.2662978 Vali Loss: 0.2713782 Test Loss: 0.2605824
Validation loss decreased (0.278834 --> 0.271378).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 0.9169790744781494
Epoch: 9, Steps: 16 | Train Loss: 0.2602717 Vali Loss: 0.2667326 Test Loss: 0.2562319
Validation loss decreased (0.271378 --> 0.266733).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 0.9230871200561523
Epoch: 10, Steps: 16 | Train Loss: 0.2562231 Vali Loss: 0.2649192 Test Loss: 0.2534770
Validation loss decreased (0.266733 --> 0.264919).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 0.9146077632904053
Epoch: 11, Steps: 16 | Train Loss: 0.2536928 Vali Loss: 0.2629907 Test Loss: 0.2516053
Validation loss decreased (0.264919 --> 0.262991).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 0.9303603172302246
Epoch: 12, Steps: 16 | Train Loss: 0.2519634 Vali Loss: 0.2609945 Test Loss: 0.2502468
Validation loss decreased (0.262991 --> 0.260994).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 0.9139702320098877
Epoch: 13, Steps: 16 | Train Loss: 0.2504431 Vali Loss: 0.2602685 Test Loss: 0.2491974
Validation loss decreased (0.260994 --> 0.260269).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 0.9130344390869141
Epoch: 14, Steps: 16 | Train Loss: 0.2492416 Vali Loss: 0.2598993 Test Loss: 0.2483537
Validation loss decreased (0.260269 --> 0.259899).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 0.9289181232452393
Epoch: 15, Steps: 16 | Train Loss: 0.2483471 Vali Loss: 0.2587048 Test Loss: 0.2476493
Validation loss decreased (0.259899 --> 0.258705).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 0.9677374362945557
Epoch: 16, Steps: 16 | Train Loss: 0.2475239 Vali Loss: 0.2586113 Test Loss: 0.2470520
Validation loss decreased (0.258705 --> 0.258611).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 0.9176690578460693
Epoch: 17, Steps: 16 | Train Loss: 0.2467685 Vali Loss: 0.2578122 Test Loss: 0.2465343
Validation loss decreased (0.258611 --> 0.257812).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 0.9322810173034668
Epoch: 18, Steps: 16 | Train Loss: 0.2462613 Vali Loss: 0.2581481 Test Loss: 0.2460829
EarlyStopping counter: 1 out of 100
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 0.9103362560272217
Epoch: 19, Steps: 16 | Train Loss: 0.2455513 Vali Loss: 0.2567756 Test Loss: 0.2456873
Validation loss decreased (0.257812 --> 0.256776).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 0.906538724899292
Epoch: 20, Steps: 16 | Train Loss: 0.2451162 Vali Loss: 0.2561567 Test Loss: 0.2453377
Validation loss decreased (0.256776 --> 0.256157).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 0.9333803653717041
Epoch: 21, Steps: 16 | Train Loss: 0.2446297 Vali Loss: 0.2559749 Test Loss: 0.2450280
Validation loss decreased (0.256157 --> 0.255975).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 0.9615473747253418
Epoch: 22, Steps: 16 | Train Loss: 0.2442403 Vali Loss: 0.2555300 Test Loss: 0.2447526
Validation loss decreased (0.255975 --> 0.255530).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 0.9151721000671387
Epoch: 23, Steps: 16 | Train Loss: 0.2439671 Vali Loss: 0.2560295 Test Loss: 0.2445067
EarlyStopping counter: 1 out of 100
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 0.9169976711273193
Epoch: 24, Steps: 16 | Train Loss: 0.2435246 Vali Loss: 0.2549722 Test Loss: 0.2442878
Validation loss decreased (0.255530 --> 0.254972).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 0.9267580509185791
Epoch: 25, Steps: 16 | Train Loss: 0.2433565 Vali Loss: 0.2552997 Test Loss: 0.2440919
EarlyStopping counter: 1 out of 100
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 0.927060604095459
Epoch: 26, Steps: 16 | Train Loss: 0.2431144 Vali Loss: 0.2549705 Test Loss: 0.2439166
Validation loss decreased (0.254972 --> 0.254970).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 0.9183809757232666
Epoch: 27, Steps: 16 | Train Loss: 0.2429217 Vali Loss: 0.2549482 Test Loss: 0.2437595
Validation loss decreased (0.254970 --> 0.254948).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 0.9120118618011475
Epoch: 28, Steps: 16 | Train Loss: 0.2427469 Vali Loss: 0.2545549 Test Loss: 0.2436190
Validation loss decreased (0.254948 --> 0.254555).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 0.9023194313049316
Epoch: 29, Steps: 16 | Train Loss: 0.2425536 Vali Loss: 0.2550792 Test Loss: 0.2434926
EarlyStopping counter: 1 out of 100
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 0.919222354888916
Epoch: 30, Steps: 16 | Train Loss: 0.2423725 Vali Loss: 0.2557266 Test Loss: 0.2433796
EarlyStopping counter: 2 out of 100
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 0.9338855743408203
Epoch: 31, Steps: 16 | Train Loss: 0.2420770 Vali Loss: 0.2554038 Test Loss: 0.2432779
EarlyStopping counter: 3 out of 100
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 1.0663800239562988
Epoch: 32, Steps: 16 | Train Loss: 0.2421320 Vali Loss: 0.2547443 Test Loss: 0.2431867
EarlyStopping counter: 4 out of 100
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 1.5028982162475586
Epoch: 33, Steps: 16 | Train Loss: 0.2419526 Vali Loss: 0.2540307 Test Loss: 0.2431045
Validation loss decreased (0.254555 --> 0.254031).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 0.9261102676391602
Epoch: 34, Steps: 16 | Train Loss: 0.2418935 Vali Loss: 0.2540776 Test Loss: 0.2430309
EarlyStopping counter: 1 out of 100
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 0.9154303073883057
Epoch: 35, Steps: 16 | Train Loss: 0.2419011 Vali Loss: 0.2542125 Test Loss: 0.2429645
EarlyStopping counter: 2 out of 100
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 0.9781556129455566
Epoch: 36, Steps: 16 | Train Loss: 0.2416454 Vali Loss: 0.2550325 Test Loss: 0.2429047
EarlyStopping counter: 3 out of 100
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 0.9277784824371338
Epoch: 37, Steps: 16 | Train Loss: 0.2417246 Vali Loss: 0.2538463 Test Loss: 0.2428510
Validation loss decreased (0.254031 --> 0.253846).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 0.9121963977813721
Epoch: 38, Steps: 16 | Train Loss: 0.2416674 Vali Loss: 0.2540296 Test Loss: 0.2428025
EarlyStopping counter: 1 out of 100
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 0.9184060096740723
Epoch: 39, Steps: 16 | Train Loss: 0.2415046 Vali Loss: 0.2543707 Test Loss: 0.2427590
EarlyStopping counter: 2 out of 100
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 0.9337825775146484
Epoch: 40, Steps: 16 | Train Loss: 0.2414601 Vali Loss: 0.2543458 Test Loss: 0.2427198
EarlyStopping counter: 3 out of 100
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 0.9158017635345459
Epoch: 41, Steps: 16 | Train Loss: 0.2412274 Vali Loss: 0.2541671 Test Loss: 0.2426846
EarlyStopping counter: 4 out of 100
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 0.9315147399902344
Epoch: 42, Steps: 16 | Train Loss: 0.2413556 Vali Loss: 0.2542714 Test Loss: 0.2426528
EarlyStopping counter: 5 out of 100
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 0.9318087100982666
Epoch: 43, Steps: 16 | Train Loss: 0.2412423 Vali Loss: 0.2538847 Test Loss: 0.2426243
EarlyStopping counter: 6 out of 100
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 0.9163191318511963
Epoch: 44, Steps: 16 | Train Loss: 0.2413839 Vali Loss: 0.2549532 Test Loss: 0.2425986
EarlyStopping counter: 7 out of 100
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 0.9218053817749023
Epoch: 45, Steps: 16 | Train Loss: 0.2413069 Vali Loss: 0.2543586 Test Loss: 0.2425754
EarlyStopping counter: 8 out of 100
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 0.915215253829956
Epoch: 46, Steps: 16 | Train Loss: 0.2412903 Vali Loss: 0.2536989 Test Loss: 0.2425545
Validation loss decreased (0.253846 --> 0.253699).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 0.964104413986206
Epoch: 47, Steps: 16 | Train Loss: 0.2410137 Vali Loss: 0.2540795 Test Loss: 0.2425357
EarlyStopping counter: 1 out of 100
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 0.9066431522369385
Epoch: 48, Steps: 16 | Train Loss: 0.2411597 Vali Loss: 0.2536266 Test Loss: 0.2425188
Validation loss decreased (0.253699 --> 0.253627).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 0.9243838787078857
Epoch: 49, Steps: 16 | Train Loss: 0.2412090 Vali Loss: 0.2538733 Test Loss: 0.2425035
EarlyStopping counter: 1 out of 100
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 0.9377291202545166
Epoch: 50, Steps: 16 | Train Loss: 0.2410873 Vali Loss: 0.2534823 Test Loss: 0.2424898
Validation loss decreased (0.253627 --> 0.253482).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 0.9241039752960205
Epoch: 51, Steps: 16 | Train Loss: 0.2411522 Vali Loss: 0.2536437 Test Loss: 0.2424774
EarlyStopping counter: 1 out of 100
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 0.9148783683776855
Epoch: 52, Steps: 16 | Train Loss: 0.2410761 Vali Loss: 0.2542412 Test Loss: 0.2424663
EarlyStopping counter: 2 out of 100
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 0.9296085834503174
Epoch: 53, Steps: 16 | Train Loss: 0.2410070 Vali Loss: 0.2539075 Test Loss: 0.2424562
EarlyStopping counter: 3 out of 100
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 0.934880256652832
Epoch: 54, Steps: 16 | Train Loss: 0.2410729 Vali Loss: 0.2538565 Test Loss: 0.2424472
EarlyStopping counter: 4 out of 100
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 0.9262819290161133
Epoch: 55, Steps: 16 | Train Loss: 0.2411163 Vali Loss: 0.2540548 Test Loss: 0.2424390
EarlyStopping counter: 5 out of 100
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 0.974754810333252
Epoch: 56, Steps: 16 | Train Loss: 0.2408649 Vali Loss: 0.2541049 Test Loss: 0.2424317
EarlyStopping counter: 6 out of 100
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 0.9366765022277832
Epoch: 57, Steps: 16 | Train Loss: 0.2409571 Vali Loss: 0.2540807 Test Loss: 0.2424251
EarlyStopping counter: 7 out of 100
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 1.3566505908966064
Epoch: 58, Steps: 16 | Train Loss: 0.2409092 Vali Loss: 0.2536713 Test Loss: 0.2424191
EarlyStopping counter: 8 out of 100
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 1.185056447982788
Epoch: 59, Steps: 16 | Train Loss: 0.2412085 Vali Loss: 0.2541538 Test Loss: 0.2424137
EarlyStopping counter: 9 out of 100
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 0.9352264404296875
Epoch: 60, Steps: 16 | Train Loss: 0.2410610 Vali Loss: 0.2540641 Test Loss: 0.2424089
EarlyStopping counter: 10 out of 100
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 0.9199662208557129
Epoch: 61, Steps: 16 | Train Loss: 0.2409508 Vali Loss: 0.2540127 Test Loss: 0.2424046
EarlyStopping counter: 11 out of 100
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 0.9210700988769531
Epoch: 62, Steps: 16 | Train Loss: 0.2410009 Vali Loss: 0.2534579 Test Loss: 0.2424006
Validation loss decreased (0.253482 --> 0.253458).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 0.9421041011810303
Epoch: 63, Steps: 16 | Train Loss: 0.2409692 Vali Loss: 0.2538824 Test Loss: 0.2423971
EarlyStopping counter: 1 out of 100
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 0.9188902378082275
Epoch: 64, Steps: 16 | Train Loss: 0.2410063 Vali Loss: 0.2535775 Test Loss: 0.2423940
EarlyStopping counter: 2 out of 100
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 0.9054090976715088
Epoch: 65, Steps: 16 | Train Loss: 0.2409508 Vali Loss: 0.2538757 Test Loss: 0.2423911
EarlyStopping counter: 3 out of 100
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 0.914703369140625
Epoch: 66, Steps: 16 | Train Loss: 0.2409467 Vali Loss: 0.2530202 Test Loss: 0.2423885
Validation loss decreased (0.253458 --> 0.253020).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 0.9348580837249756
Epoch: 67, Steps: 16 | Train Loss: 0.2409543 Vali Loss: 0.2540794 Test Loss: 0.2423862
EarlyStopping counter: 1 out of 100
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 0.9194285869598389
Epoch: 68, Steps: 16 | Train Loss: 0.2412067 Vali Loss: 0.2540546 Test Loss: 0.2423841
EarlyStopping counter: 2 out of 100
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 0.9757845401763916
Epoch: 69, Steps: 16 | Train Loss: 0.2409567 Vali Loss: 0.2533317 Test Loss: 0.2423822
EarlyStopping counter: 3 out of 100
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 0.912905216217041
Epoch: 70, Steps: 16 | Train Loss: 0.2408703 Vali Loss: 0.2542873 Test Loss: 0.2423805
EarlyStopping counter: 4 out of 100
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 0.9205121994018555
Epoch: 71, Steps: 16 | Train Loss: 0.2409265 Vali Loss: 0.2546261 Test Loss: 0.2423790
EarlyStopping counter: 5 out of 100
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 0.906470775604248
Epoch: 72, Steps: 16 | Train Loss: 0.2409288 Vali Loss: 0.2536049 Test Loss: 0.2423776
EarlyStopping counter: 6 out of 100
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 0.9381918907165527
Epoch: 73, Steps: 16 | Train Loss: 0.2408960 Vali Loss: 0.2533760 Test Loss: 0.2423764
EarlyStopping counter: 7 out of 100
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 0.9035892486572266
Epoch: 74, Steps: 16 | Train Loss: 0.2410182 Vali Loss: 0.2536734 Test Loss: 0.2423753
EarlyStopping counter: 8 out of 100
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 0.922264814376831
Epoch: 75, Steps: 16 | Train Loss: 0.2410563 Vali Loss: 0.2536359 Test Loss: 0.2423742
EarlyStopping counter: 9 out of 100
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 0.9336051940917969
Epoch: 76, Steps: 16 | Train Loss: 0.2407937 Vali Loss: 0.2539531 Test Loss: 0.2423733
EarlyStopping counter: 10 out of 100
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 0.9318580627441406
Epoch: 77, Steps: 16 | Train Loss: 0.2412378 Vali Loss: 0.2534549 Test Loss: 0.2423725
EarlyStopping counter: 11 out of 100
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 0.9175522327423096
Epoch: 78, Steps: 16 | Train Loss: 0.2408847 Vali Loss: 0.2536677 Test Loss: 0.2423718
EarlyStopping counter: 12 out of 100
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 0.921532154083252
Epoch: 79, Steps: 16 | Train Loss: 0.2409807 Vali Loss: 0.2528678 Test Loss: 0.2423711
Validation loss decreased (0.253020 --> 0.252868).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 0.9196319580078125
Epoch: 80, Steps: 16 | Train Loss: 0.2409569 Vali Loss: 0.2538884 Test Loss: 0.2423705
EarlyStopping counter: 1 out of 100
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 0.9205710887908936
Epoch: 81, Steps: 16 | Train Loss: 0.2410818 Vali Loss: 0.2537720 Test Loss: 0.2423700
EarlyStopping counter: 2 out of 100
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 0.916391134262085
Epoch: 82, Steps: 16 | Train Loss: 0.2410786 Vali Loss: 0.2549651 Test Loss: 0.2423695
EarlyStopping counter: 3 out of 100
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 0.9372718334197998
Epoch: 83, Steps: 16 | Train Loss: 0.2411302 Vali Loss: 0.2540281 Test Loss: 0.2423691
EarlyStopping counter: 4 out of 100
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 1.1651654243469238
Epoch: 84, Steps: 16 | Train Loss: 0.2409326 Vali Loss: 0.2533275 Test Loss: 0.2423687
EarlyStopping counter: 5 out of 100
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 1.4606952667236328
Epoch: 85, Steps: 16 | Train Loss: 0.2409969 Vali Loss: 0.2539757 Test Loss: 0.2423683
EarlyStopping counter: 6 out of 100
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 0.9941084384918213
Epoch: 86, Steps: 16 | Train Loss: 0.2411370 Vali Loss: 0.2538568 Test Loss: 0.2423680
EarlyStopping counter: 7 out of 100
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 0.9125173091888428
Epoch: 87, Steps: 16 | Train Loss: 0.2409036 Vali Loss: 0.2535045 Test Loss: 0.2423677
EarlyStopping counter: 8 out of 100
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 0.9373953342437744
Epoch: 88, Steps: 16 | Train Loss: 0.2408741 Vali Loss: 0.2540406 Test Loss: 0.2423675
EarlyStopping counter: 9 out of 100
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 0.9208111763000488
Epoch: 89, Steps: 16 | Train Loss: 0.2408510 Vali Loss: 0.2537088 Test Loss: 0.2423673
EarlyStopping counter: 10 out of 100
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 0.9092023372650146
Epoch: 90, Steps: 16 | Train Loss: 0.2411107 Vali Loss: 0.2532845 Test Loss: 0.2423670
EarlyStopping counter: 11 out of 100
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 0.9302854537963867
Epoch: 91, Steps: 16 | Train Loss: 0.2409575 Vali Loss: 0.2536488 Test Loss: 0.2423669
EarlyStopping counter: 12 out of 100
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 0.9348146915435791
Epoch: 92, Steps: 16 | Train Loss: 0.2409725 Vali Loss: 0.2539219 Test Loss: 0.2423667
EarlyStopping counter: 13 out of 100
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 1.0381889343261719
Epoch: 93, Steps: 16 | Train Loss: 0.2410676 Vali Loss: 0.2540843 Test Loss: 0.2423665
EarlyStopping counter: 14 out of 100
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 0.9287242889404297
Epoch: 94, Steps: 16 | Train Loss: 0.2409033 Vali Loss: 0.2535011 Test Loss: 0.2423664
EarlyStopping counter: 15 out of 100
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 0.949385404586792
Epoch: 95, Steps: 16 | Train Loss: 0.2408402 Vali Loss: 0.2533597 Test Loss: 0.2423663
EarlyStopping counter: 16 out of 100
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 0.9227676391601562
Epoch: 96, Steps: 16 | Train Loss: 0.2410184 Vali Loss: 0.2540253 Test Loss: 0.2423662
EarlyStopping counter: 17 out of 100
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 0.9552297592163086
Epoch: 97, Steps: 16 | Train Loss: 0.2410624 Vali Loss: 0.2536751 Test Loss: 0.2423661
EarlyStopping counter: 18 out of 100
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 0.9203181266784668
Epoch: 98, Steps: 16 | Train Loss: 0.2410649 Vali Loss: 0.2535765 Test Loss: 0.2423660
EarlyStopping counter: 19 out of 100
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 1.0085883140563965
Epoch: 99, Steps: 16 | Train Loss: 0.2410941 Vali Loss: 0.2529914 Test Loss: 0.2423659
EarlyStopping counter: 20 out of 100
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 0.9053518772125244
Epoch: 100, Steps: 16 | Train Loss: 0.2409879 Vali Loss: 0.2541283 Test Loss: 0.2423658
EarlyStopping counter: 21 out of 100
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : DLinear_sin_wave_336_96_DLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1256
mse:33174352560128.0, mae:2157859.75, rse:0.11924786865711212
