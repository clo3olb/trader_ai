Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='AAPL_intraday_336_96', model='PatchTST', data='custom', root_path='./data_fetcher/', data_path='merged_data.csv', result_path='./predictor/results/', features='M', target='Close', freq='h', date_header='Date', seq_len=336, label_len=48, pred_len=96, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=19, dec_in=19, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=512, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : AAPL_intraday_336_96_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 143047
val 20403
test 40898
	iters: 100, epoch: 1 | loss: 0.5470153
	speed: 0.3662s/iter; left time: 10179.4841s
	iters: 200, epoch: 1 | loss: 0.4698773
	speed: 0.3466s/iter; left time: 9600.0962s
Epoch: 1 cost time: 98.84761786460876
Epoch: 1, Steps: 279 | Train Loss: 0.5077377 Vali Loss: 0.5205556 Test Loss: 0.4904648
Validation loss decreased (inf --> 0.520556).  Saving model ...
Updating learning rate to 0.0001
