Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=256, c_out=7, d_ff=256, d_model=128, data='custom', data_path='AMZN_pct.csv', date_header='Timestamp', dec_in=19, decoder_layers=1, decomposition=1, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.2, e_layers=3, embed='timeF', embed_type=0, enc_in=19, factor=1, fc_dropout=0.2, features='M', freq='1d', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='PatchTST', model_id='PatchTST_AMZN_pct_336_96', moving_avg=25, n_heads=16, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=96, random_seed=2024, result_path='./predictor/results/', revin=1, root_path='./predictor/dataset/', seq_len=336, stride=8, subtract_last=0, target='Close', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : PatchTST_AMZN_pct_336_96>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9684
val 1351
test 2795
Epoch: 1 cost time: 44.628602504730225
Epoch: 1, Steps: 37 | Train Loss: 1.3534421 Vali Loss: 0.8109703 Test Loss: 1.3458626
Validation loss decreased (inf --> 0.810970).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 43.88888669013977
Epoch: 2, Steps: 37 | Train Loss: 1.1739128 Vali Loss: 0.7033972 Test Loss: 1.1684891
Validation loss decreased (0.810970 --> 0.703397).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 44.15335750579834
Epoch: 3, Steps: 37 | Train Loss: 1.0493047 Vali Loss: 0.6826609 Test Loss: 1.1219621
Validation loss decreased (0.703397 --> 0.682661).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 44.05200147628784
Epoch: 4, Steps: 37 | Train Loss: 1.0158822 Vali Loss: 0.6785323 Test Loss: 1.1208467
Validation loss decreased (0.682661 --> 0.678532).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 43.94045686721802
Epoch: 5, Steps: 37 | Train Loss: 0.9985695 Vali Loss: 0.6790987 Test Loss: 1.1247314
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 43.9908983707428
Epoch: 6, Steps: 37 | Train Loss: 0.9834111 Vali Loss: 0.6791900 Test Loss: 1.1270213
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 44.11556124687195
Epoch: 7, Steps: 37 | Train Loss: 0.9802495 Vali Loss: 0.6796809 Test Loss: 1.1264569
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 44.007113218307495
Epoch: 8, Steps: 37 | Train Loss: 0.9702808 Vali Loss: 0.6740554 Test Loss: 1.1230575
Validation loss decreased (0.678532 --> 0.674055).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 44.09876489639282
Epoch: 9, Steps: 37 | Train Loss: 0.9714561 Vali Loss: 0.6759037 Test Loss: 1.1284068
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 43.972713232040405
Epoch: 10, Steps: 37 | Train Loss: 0.9692641 Vali Loss: 0.6793159 Test Loss: 1.1321253
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.782969000000001e-05
