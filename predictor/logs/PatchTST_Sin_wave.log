Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='Sin_wave_336_96', model='PatchTST', data='custom', root_path='./predictor/dataset/', data_path='sin_wave.csv', result_path='./predictor/results/', features='M', target='Close', freq='1d', date_header='timestamp', seq_len=336, label_len=48, pred_len=96, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=7, d_model=128, n_heads=16, e_layers=3, decoder_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Sin_wave_336_96_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4298
val 582
test 1256
Epoch: 1 cost time: 5.527328729629517
Epoch: 1, Steps: 33 | Train Loss: 1.3237493 Vali Loss: 0.8861293 Test Loss: 0.8960649
Validation loss decreased (inf --> 0.886129).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 4.552140951156616
Epoch: 2, Steps: 33 | Train Loss: 0.7098246 Vali Loss: 0.3814079 Test Loss: 0.3891707
Validation loss decreased (0.886129 --> 0.381408).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 4.555331230163574
Epoch: 3, Steps: 33 | Train Loss: 0.2619590 Vali Loss: 0.0595273 Test Loss: 0.0603275
Validation loss decreased (0.381408 --> 0.059527).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 4.897911310195923
Epoch: 4, Steps: 33 | Train Loss: 0.1281349 Vali Loss: 0.0373733 Test Loss: 0.0378243
Validation loss decreased (0.059527 --> 0.037373).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 4.576223611831665
Epoch: 5, Steps: 33 | Train Loss: 0.0810125 Vali Loss: 0.0155601 Test Loss: 0.0157738
Validation loss decreased (0.037373 --> 0.015560).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 4.595763206481934
Epoch: 6, Steps: 33 | Train Loss: 0.0587450 Vali Loss: 0.0068376 Test Loss: 0.0069130
Validation loss decreased (0.015560 --> 0.006838).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 4.667242527008057
Epoch: 7, Steps: 33 | Train Loss: 0.0468967 Vali Loss: 0.0035474 Test Loss: 0.0036162
Validation loss decreased (0.006838 --> 0.003547).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 4.640588045120239
Epoch: 8, Steps: 33 | Train Loss: 0.0391629 Vali Loss: 0.0021143 Test Loss: 0.0021459
Validation loss decreased (0.003547 --> 0.002114).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 4.832794666290283
Epoch: 9, Steps: 33 | Train Loss: 0.0346018 Vali Loss: 0.0014020 Test Loss: 0.0014249
Validation loss decreased (0.002114 --> 0.001402).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 4.671855926513672
Epoch: 10, Steps: 33 | Train Loss: 0.0321265 Vali Loss: 0.0008873 Test Loss: 0.0008976
Validation loss decreased (0.001402 --> 0.000887).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 4.661362886428833
Epoch: 11, Steps: 33 | Train Loss: 0.0304120 Vali Loss: 0.0007059 Test Loss: 0.0007138
Validation loss decreased (0.000887 --> 0.000706).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 4.708234071731567
Epoch: 12, Steps: 33 | Train Loss: 0.0292550 Vali Loss: 0.0005785 Test Loss: 0.0005848
Validation loss decreased (0.000706 --> 0.000579).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 4.710690498352051
Epoch: 13, Steps: 33 | Train Loss: 0.0284331 Vali Loss: 0.0004714 Test Loss: 0.0004771
Validation loss decreased (0.000579 --> 0.000471).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 4.705744028091431
Epoch: 14, Steps: 33 | Train Loss: 0.0276481 Vali Loss: 0.0004057 Test Loss: 0.0004090
Validation loss decreased (0.000471 --> 0.000406).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 4.68363356590271
Epoch: 15, Steps: 33 | Train Loss: 0.0270505 Vali Loss: 0.0003432 Test Loss: 0.0003442
Validation loss decreased (0.000406 --> 0.000343).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 4.737274646759033
Epoch: 16, Steps: 33 | Train Loss: 0.0265605 Vali Loss: 0.0003131 Test Loss: 0.0003141
Validation loss decreased (0.000343 --> 0.000313).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 4.714614152908325
Epoch: 17, Steps: 33 | Train Loss: 0.0261450 Vali Loss: 0.0002865 Test Loss: 0.0002864
Validation loss decreased (0.000313 --> 0.000286).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 4.729108095169067
Epoch: 18, Steps: 33 | Train Loss: 0.0257621 Vali Loss: 0.0002612 Test Loss: 0.0002609
Validation loss decreased (0.000286 --> 0.000261).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 4.99286150932312
Epoch: 19, Steps: 33 | Train Loss: 0.0254574 Vali Loss: 0.0002326 Test Loss: 0.0002324
Validation loss decreased (0.000261 --> 0.000233).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 4.776254415512085
Epoch: 20, Steps: 33 | Train Loss: 0.0252243 Vali Loss: 0.0002176 Test Loss: 0.0002173
Validation loss decreased (0.000233 --> 0.000218).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 4.859157562255859
Epoch: 21, Steps: 33 | Train Loss: 0.0249493 Vali Loss: 0.0002072 Test Loss: 0.0002072
Validation loss decreased (0.000218 --> 0.000207).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 4.768839120864868
Epoch: 22, Steps: 33 | Train Loss: 0.0247395 Vali Loss: 0.0002054 Test Loss: 0.0002049
Validation loss decreased (0.000207 --> 0.000205).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 4.754002332687378
Epoch: 23, Steps: 33 | Train Loss: 0.0245140 Vali Loss: 0.0001906 Test Loss: 0.0001894
Validation loss decreased (0.000205 --> 0.000191).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 4.778555154800415
Epoch: 24, Steps: 33 | Train Loss: 0.0243580 Vali Loss: 0.0001834 Test Loss: 0.0001825
Validation loss decreased (0.000191 --> 0.000183).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 4.792161464691162
Epoch: 25, Steps: 33 | Train Loss: 0.0241759 Vali Loss: 0.0001712 Test Loss: 0.0001714
Validation loss decreased (0.000183 --> 0.000171).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 4.775155544281006
Epoch: 26, Steps: 33 | Train Loss: 0.0241180 Vali Loss: 0.0001635 Test Loss: 0.0001637
Validation loss decreased (0.000171 --> 0.000164).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 4.817026138305664
Epoch: 27, Steps: 33 | Train Loss: 0.0239317 Vali Loss: 0.0001591 Test Loss: 0.0001587
Validation loss decreased (0.000164 --> 0.000159).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 5.004425525665283
Epoch: 28, Steps: 33 | Train Loss: 0.0238414 Vali Loss: 0.0001563 Test Loss: 0.0001562
Validation loss decreased (0.000159 --> 0.000156).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 4.800889253616333
Epoch: 29, Steps: 33 | Train Loss: 0.0237666 Vali Loss: 0.0001536 Test Loss: 0.0001527
Validation loss decreased (0.000156 --> 0.000154).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 4.817852258682251
Epoch: 30, Steps: 33 | Train Loss: 0.0236641 Vali Loss: 0.0001462 Test Loss: 0.0001459
Validation loss decreased (0.000154 --> 0.000146).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 4.828253507614136
Epoch: 31, Steps: 33 | Train Loss: 0.0235592 Vali Loss: 0.0001448 Test Loss: 0.0001445
Validation loss decreased (0.000146 --> 0.000145).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 4.845781087875366
Epoch: 32, Steps: 33 | Train Loss: 0.0234836 Vali Loss: 0.0001415 Test Loss: 0.0001415
Validation loss decreased (0.000145 --> 0.000141).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 4.8457159996032715
Epoch: 33, Steps: 33 | Train Loss: 0.0234496 Vali Loss: 0.0001404 Test Loss: 0.0001399
Validation loss decreased (0.000141 --> 0.000140).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 4.8447206020355225
Epoch: 34, Steps: 33 | Train Loss: 0.0233966 Vali Loss: 0.0001371 Test Loss: 0.0001369
Validation loss decreased (0.000140 --> 0.000137).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 4.8124449253082275
Epoch: 35, Steps: 33 | Train Loss: 0.0233000 Vali Loss: 0.0001353 Test Loss: 0.0001346
Validation loss decreased (0.000137 --> 0.000135).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 4.822937965393066
Epoch: 36, Steps: 33 | Train Loss: 0.0232750 Vali Loss: 0.0001312 Test Loss: 0.0001310
Validation loss decreased (0.000135 --> 0.000131).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 4.987208127975464
Epoch: 37, Steps: 33 | Train Loss: 0.0232237 Vali Loss: 0.0001335 Test Loss: 0.0001332
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 4.817354440689087
Epoch: 38, Steps: 33 | Train Loss: 0.0231835 Vali Loss: 0.0001299 Test Loss: 0.0001296
Validation loss decreased (0.000131 --> 0.000130).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 4.793542385101318
Epoch: 39, Steps: 33 | Train Loss: 0.0231708 Vali Loss: 0.0001272 Test Loss: 0.0001271
Validation loss decreased (0.000130 --> 0.000127).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 4.794754505157471
Epoch: 40, Steps: 33 | Train Loss: 0.0231281 Vali Loss: 0.0001245 Test Loss: 0.0001240
Validation loss decreased (0.000127 --> 0.000124).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 4.869142293930054
Epoch: 41, Steps: 33 | Train Loss: 0.0230980 Vali Loss: 0.0001231 Test Loss: 0.0001228
Validation loss decreased (0.000124 --> 0.000123).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 4.851354598999023
Epoch: 42, Steps: 33 | Train Loss: 0.0230889 Vali Loss: 0.0001251 Test Loss: 0.0001250
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 4.784189701080322
Epoch: 43, Steps: 33 | Train Loss: 0.0230323 Vali Loss: 0.0001238 Test Loss: 0.0001235
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 4.809184312820435
Epoch: 44, Steps: 33 | Train Loss: 0.0230054 Vali Loss: 0.0001216 Test Loss: 0.0001213
Validation loss decreased (0.000123 --> 0.000122).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 4.828630685806274
Epoch: 45, Steps: 33 | Train Loss: 0.0229485 Vali Loss: 0.0001194 Test Loss: 0.0001193
Validation loss decreased (0.000122 --> 0.000119).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 4.974026918411255
Epoch: 46, Steps: 33 | Train Loss: 0.0229215 Vali Loss: 0.0001192 Test Loss: 0.0001191
Validation loss decreased (0.000119 --> 0.000119).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 5.061627626419067
Epoch: 47, Steps: 33 | Train Loss: 0.0229197 Vali Loss: 0.0001189 Test Loss: 0.0001189
Validation loss decreased (0.000119 --> 0.000119).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 4.8137571811676025
Epoch: 48, Steps: 33 | Train Loss: 0.0228664 Vali Loss: 0.0001184 Test Loss: 0.0001182
Validation loss decreased (0.000119 --> 0.000118).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 4.878378868103027
Epoch: 49, Steps: 33 | Train Loss: 0.0229177 Vali Loss: 0.0001211 Test Loss: 0.0001209
EarlyStopping counter: 1 out of 20
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 4.832578420639038
Epoch: 50, Steps: 33 | Train Loss: 0.0228910 Vali Loss: 0.0001205 Test Loss: 0.0001200
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 4.811860084533691
Epoch: 51, Steps: 33 | Train Loss: 0.0229095 Vali Loss: 0.0001178 Test Loss: 0.0001175
Validation loss decreased (0.000118 --> 0.000118).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 4.830971956253052
Epoch: 52, Steps: 33 | Train Loss: 0.0228536 Vali Loss: 0.0001173 Test Loss: 0.0001170
Validation loss decreased (0.000118 --> 0.000117).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 4.863765239715576
Epoch: 53, Steps: 33 | Train Loss: 0.0228076 Vali Loss: 0.0001169 Test Loss: 0.0001166
Validation loss decreased (0.000117 --> 0.000117).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 5.125620603561401
Epoch: 54, Steps: 33 | Train Loss: 0.0228321 Vali Loss: 0.0001161 Test Loss: 0.0001157
Validation loss decreased (0.000117 --> 0.000116).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 4.959897994995117
Epoch: 55, Steps: 33 | Train Loss: 0.0228351 Vali Loss: 0.0001166 Test Loss: 0.0001163
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 5.242340803146362
Epoch: 56, Steps: 33 | Train Loss: 0.0228177 Vali Loss: 0.0001150 Test Loss: 0.0001149
Validation loss decreased (0.000116 --> 0.000115).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 4.870389461517334
Epoch: 57, Steps: 33 | Train Loss: 0.0228912 Vali Loss: 0.0001156 Test Loss: 0.0001153
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 4.77493691444397
Epoch: 58, Steps: 33 | Train Loss: 0.0228004 Vali Loss: 0.0001166 Test Loss: 0.0001165
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 4.809358358383179
Epoch: 59, Steps: 33 | Train Loss: 0.0227642 Vali Loss: 0.0001191 Test Loss: 0.0001188
EarlyStopping counter: 3 out of 20
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 4.818226099014282
Epoch: 60, Steps: 33 | Train Loss: 0.0228215 Vali Loss: 0.0001140 Test Loss: 0.0001136
Validation loss decreased (0.000115 --> 0.000114).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 4.885230779647827
Epoch: 61, Steps: 33 | Train Loss: 0.0227836 Vali Loss: 0.0001156 Test Loss: 0.0001154
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 4.812023639678955
Epoch: 62, Steps: 33 | Train Loss: 0.0227999 Vali Loss: 0.0001173 Test Loss: 0.0001171
EarlyStopping counter: 2 out of 20
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 4.850570201873779
Epoch: 63, Steps: 33 | Train Loss: 0.0228037 Vali Loss: 0.0001155 Test Loss: 0.0001155
EarlyStopping counter: 3 out of 20
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 4.8372251987457275
Epoch: 64, Steps: 33 | Train Loss: 0.0227570 Vali Loss: 0.0001142 Test Loss: 0.0001140
EarlyStopping counter: 4 out of 20
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 5.127125978469849
Epoch: 65, Steps: 33 | Train Loss: 0.0227309 Vali Loss: 0.0001148 Test Loss: 0.0001145
EarlyStopping counter: 5 out of 20
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 4.838899612426758
Epoch: 66, Steps: 33 | Train Loss: 0.0228159 Vali Loss: 0.0001149 Test Loss: 0.0001147
EarlyStopping counter: 6 out of 20
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 4.880070209503174
Epoch: 67, Steps: 33 | Train Loss: 0.0227226 Vali Loss: 0.0001142 Test Loss: 0.0001141
EarlyStopping counter: 7 out of 20
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 4.809451580047607
Epoch: 68, Steps: 33 | Train Loss: 0.0227493 Vali Loss: 0.0001144 Test Loss: 0.0001143
EarlyStopping counter: 8 out of 20
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 4.808557748794556
Epoch: 69, Steps: 33 | Train Loss: 0.0227626 Vali Loss: 0.0001133 Test Loss: 0.0001132
Validation loss decreased (0.000114 --> 0.000113).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 4.8233630657196045
Epoch: 70, Steps: 33 | Train Loss: 0.0227467 Vali Loss: 0.0001164 Test Loss: 0.0001163
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 4.900543451309204
Epoch: 71, Steps: 33 | Train Loss: 0.0227130 Vali Loss: 0.0001131 Test Loss: 0.0001131
Validation loss decreased (0.000113 --> 0.000113).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 4.82983136177063
Epoch: 72, Steps: 33 | Train Loss: 0.0227441 Vali Loss: 0.0001120 Test Loss: 0.0001118
Validation loss decreased (0.000113 --> 0.000112).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 4.829935550689697
Epoch: 73, Steps: 33 | Train Loss: 0.0227397 Vali Loss: 0.0001142 Test Loss: 0.0001140
EarlyStopping counter: 1 out of 20
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 5.056482553482056
Epoch: 74, Steps: 33 | Train Loss: 0.0227527 Vali Loss: 0.0001131 Test Loss: 0.0001130
EarlyStopping counter: 2 out of 20
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 4.86794376373291
Epoch: 75, Steps: 33 | Train Loss: 0.0227432 Vali Loss: 0.0001139 Test Loss: 0.0001133
EarlyStopping counter: 3 out of 20
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 4.8675572872161865
Epoch: 76, Steps: 33 | Train Loss: 0.0227960 Vali Loss: 0.0001135 Test Loss: 0.0001132
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 4.853633165359497
Epoch: 77, Steps: 33 | Train Loss: 0.0228126 Vali Loss: 0.0001134 Test Loss: 0.0001130
EarlyStopping counter: 5 out of 20
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 4.818647861480713
Epoch: 78, Steps: 33 | Train Loss: 0.0227978 Vali Loss: 0.0001161 Test Loss: 0.0001158
EarlyStopping counter: 6 out of 20
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 4.802374839782715
Epoch: 79, Steps: 33 | Train Loss: 0.0227767 Vali Loss: 0.0001127 Test Loss: 0.0001123
EarlyStopping counter: 7 out of 20
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 4.820650339126587
Epoch: 80, Steps: 33 | Train Loss: 0.0227205 Vali Loss: 0.0001125 Test Loss: 0.0001123
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 4.792022466659546
Epoch: 81, Steps: 33 | Train Loss: 0.0227723 Vali Loss: 0.0001137 Test Loss: 0.0001133
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 4.786455392837524
Epoch: 82, Steps: 33 | Train Loss: 0.0227001 Vali Loss: 0.0001132 Test Loss: 0.0001131
EarlyStopping counter: 10 out of 20
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 4.900607585906982
Epoch: 83, Steps: 33 | Train Loss: 0.0227406 Vali Loss: 0.0001137 Test Loss: 0.0001136
EarlyStopping counter: 11 out of 20
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 4.817084312438965
Epoch: 84, Steps: 33 | Train Loss: 0.0227651 Vali Loss: 0.0001134 Test Loss: 0.0001131
EarlyStopping counter: 12 out of 20
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 4.818748474121094
Epoch: 85, Steps: 33 | Train Loss: 0.0227427 Vali Loss: 0.0001121 Test Loss: 0.0001118
EarlyStopping counter: 13 out of 20
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 4.83456826210022
Epoch: 86, Steps: 33 | Train Loss: 0.0226900 Vali Loss: 0.0001131 Test Loss: 0.0001129
EarlyStopping counter: 14 out of 20
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 4.82598614692688
Epoch: 87, Steps: 33 | Train Loss: 0.0227613 Vali Loss: 0.0001144 Test Loss: 0.0001142
EarlyStopping counter: 15 out of 20
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 4.839404582977295
Epoch: 88, Steps: 33 | Train Loss: 0.0227081 Vali Loss: 0.0001122 Test Loss: 0.0001120
EarlyStopping counter: 16 out of 20
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 4.808866024017334
Epoch: 89, Steps: 33 | Train Loss: 0.0226979 Vali Loss: 0.0001109 Test Loss: 0.0001107
Validation loss decreased (0.000112 --> 0.000111).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 4.851792573928833
Epoch: 90, Steps: 33 | Train Loss: 0.0227595 Vali Loss: 0.0001127 Test Loss: 0.0001124
EarlyStopping counter: 1 out of 20
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 4.808016300201416
Epoch: 91, Steps: 33 | Train Loss: 0.0227140 Vali Loss: 0.0001122 Test Loss: 0.0001118
EarlyStopping counter: 2 out of 20
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 4.969057083129883
Epoch: 92, Steps: 33 | Train Loss: 0.0227747 Vali Loss: 0.0001127 Test Loss: 0.0001126
EarlyStopping counter: 3 out of 20
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 5.10430908203125
Epoch: 93, Steps: 33 | Train Loss: 0.0227219 Vali Loss: 0.0001134 Test Loss: 0.0001131
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 4.809409141540527
Epoch: 94, Steps: 33 | Train Loss: 0.0227768 Vali Loss: 0.0001117 Test Loss: 0.0001114
EarlyStopping counter: 5 out of 20
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 4.848804235458374
Epoch: 95, Steps: 33 | Train Loss: 0.0227238 Vali Loss: 0.0001103 Test Loss: 0.0001103
Validation loss decreased (0.000111 --> 0.000110).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 4.865344524383545
Epoch: 96, Steps: 33 | Train Loss: 0.0227066 Vali Loss: 0.0001134 Test Loss: 0.0001133
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 4.830023288726807
Epoch: 97, Steps: 33 | Train Loss: 0.0227992 Vali Loss: 0.0001116 Test Loss: 0.0001115
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 4.817532062530518
Epoch: 98, Steps: 33 | Train Loss: 0.0227663 Vali Loss: 0.0001137 Test Loss: 0.0001135
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 4.825118064880371
Epoch: 99, Steps: 33 | Train Loss: 0.0227221 Vali Loss: 0.0001163 Test Loss: 0.0001160
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 4.825268745422363
Epoch: 100, Steps: 33 | Train Loss: 0.0227447 Vali Loss: 0.0001118 Test Loss: 0.0001115
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : Sin_wave_336_96_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1256
mse:5.4887121223146096e-05, mae:0.005852811504155397, rse:0.010473264381289482
