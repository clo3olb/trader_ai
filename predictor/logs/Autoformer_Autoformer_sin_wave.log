Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='Autoformer_sin_wave_336_96', model='Autoformer', data='custom', root_path='./predictor/dataset/', data_path='sin_wave.csv', result_path='./predictor/results/', features='M', target='Close', freq='d', date_header='Timestamp', seq_len=336, label_len=48, pred_len=96, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, decoder_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=256, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Autoformer_sin_wave_336_96_Autoformer_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4298
val 582
test 1256
Epoch: 1 cost time: 8.99629259109497
Epoch: 1, Steps: 16 | Train Loss: 1.6130729 Vali Loss: 1.5539625 Test Loss: 1.5677049
Validation loss decreased (inf --> 1.553962).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 6.658437728881836
Epoch: 2, Steps: 16 | Train Loss: 1.4878384 Vali Loss: 1.3269138 Test Loss: 1.3344822
Validation loss decreased (1.553962 --> 1.326914).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 6.437277555465698
Epoch: 3, Steps: 16 | Train Loss: 1.3782854 Vali Loss: 1.2842016 Test Loss: 1.2778729
Validation loss decreased (1.326914 --> 1.284202).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 6.43909764289856
Epoch: 4, Steps: 16 | Train Loss: 1.3339038 Vali Loss: 1.2776971 Test Loss: 1.2563108
Validation loss decreased (1.284202 --> 1.277697).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 6.416480302810669
Epoch: 5, Steps: 16 | Train Loss: 1.3078608 Vali Loss: 1.2797600 Test Loss: 1.2460697
EarlyStopping counter: 1 out of 20
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 6.4789392948150635
Epoch: 6, Steps: 16 | Train Loss: 1.2896168 Vali Loss: 1.2792284 Test Loss: 1.2426745
EarlyStopping counter: 2 out of 20
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 6.534718751907349
Epoch: 7, Steps: 16 | Train Loss: 1.2775740 Vali Loss: 1.2781143 Test Loss: 1.2389292
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 7.067378997802734
Epoch: 8, Steps: 16 | Train Loss: 1.2685845 Vali Loss: 1.2806650 Test Loss: 1.2356830
EarlyStopping counter: 4 out of 20
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 6.586835861206055
Epoch: 9, Steps: 16 | Train Loss: 1.2571970 Vali Loss: 1.2751663 Test Loss: 1.2342007
Validation loss decreased (1.277697 --> 1.275166).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 6.547757625579834
Epoch: 10, Steps: 16 | Train Loss: 1.2495398 Vali Loss: 1.2828243 Test Loss: 1.2330813
EarlyStopping counter: 1 out of 20
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 6.5466649532318115
Epoch: 11, Steps: 16 | Train Loss: 1.2424099 Vali Loss: 1.2831458 Test Loss: 1.2323059
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 6.6081342697143555
Epoch: 12, Steps: 16 | Train Loss: 1.2359486 Vali Loss: 1.2763355 Test Loss: 1.2313931
EarlyStopping counter: 3 out of 20
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 6.5838611125946045
Epoch: 13, Steps: 16 | Train Loss: 1.2296244 Vali Loss: 1.2768234 Test Loss: 1.2312598
EarlyStopping counter: 4 out of 20
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 6.667567491531372
Epoch: 14, Steps: 16 | Train Loss: 1.2216299 Vali Loss: 1.2774736 Test Loss: 1.2311574
EarlyStopping counter: 5 out of 20
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 6.701632976531982
Epoch: 15, Steps: 16 | Train Loss: 1.2166710 Vali Loss: 1.2774060 Test Loss: 1.2301934
EarlyStopping counter: 6 out of 20
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 6.694077253341675
Epoch: 16, Steps: 16 | Train Loss: 1.2109659 Vali Loss: 1.2789650 Test Loss: 1.2292993
EarlyStopping counter: 7 out of 20
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 6.728950500488281
Epoch: 17, Steps: 16 | Train Loss: 1.2034074 Vali Loss: 1.2778034 Test Loss: 1.2290579
EarlyStopping counter: 8 out of 20
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 6.784574508666992
Epoch: 18, Steps: 16 | Train Loss: 1.1999240 Vali Loss: 1.2753797 Test Loss: 1.2286409
EarlyStopping counter: 9 out of 20
Updating learning rate to 2.0589113209464907e-05
